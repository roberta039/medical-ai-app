import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from PIL import Image
from tavily import TavilyClient
import re

# --- 1. CONFIGURARE PAGINÄ‚ & STIL ---
st.set_page_config(page_title="MediChat AI Pro", page_icon="ğŸ©º", layout="wide")

# CSS pentru a face chat-ul mai lizibil
st.markdown("""
    <style>
    .stChatMessage { font-family: 'Arial', sans-serif; }
    .stButton button { width: 100%; border-radius: 8px; }
    div[data-testid="stToast"] { padding: 1rem; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. DISCLAIMER OBLIGATORIU ---
st.warning("âš ï¸ **AVERTISMENT MEDICAL:** Acest asistent AI este un prototip experimental. RÄƒspunsurile pot fi inexacte sau halucinate. VerificaÈ›i Ã®ntotdeauna informaÈ›iile cu ghiduri clinice oficiale. Nu introduceÈ›i date personale care pot identifica pacienÈ›ii (Nume, CNP, AdresÄƒ).")

# --- 3. VERIFICARE API KEYS ---
if "GOOGLE_API_KEY" not in st.secrets or "TAVILY_API_KEY" not in st.secrets:
    st.error("âš ï¸ Lipsesc cheile API! SeteazÄƒ `GOOGLE_API_KEY` È™i `TAVILY_API_KEY` Ã®n Streamlit Secrets.")
    st.stop()

# Configurare Clienti
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
tavily = TavilyClient(api_key=st.secrets["TAVILY_API_KEY"])

# --- 4. FUNCÈšII UTILITARE & MODEL ---

@st.cache_resource
def load_best_model():
    """GÄƒseÈ™te cel mai bun model Gemini disponibil pe cont."""
    try:
        all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # Prioritate: Flash (rapid) -> Pro (complex) -> Orice altceva
        chosen_model = next((m for m in all_models if "flash" in m and "1.5" in m), None)
        if not chosen_model:
            chosen_model = next((m for m in all_models if "pro" in m and "1.5" in m), all_models[0])
            
        return genai.GenerativeModel(chosen_model), chosen_model
    except Exception as e:
        return None, str(e)

model, model_name = load_best_model()

if not model:
    st.error("âŒ Nu am putut Ã®ncÄƒrca modelul AI. VerificÄƒ API Key-ul.")
    st.stop()

def search_tavily(query):
    """CautÄƒ pe site-uri medicale de Ã®ncredere."""
    try:
        response = tavily.search(
            query=query, 
            search_depth="advanced", 
            max_results=5,
            include_domains=["nih.gov", "pubmed.ncbi.nlm.nih.gov", "escardio.org", "heart.org", "who.int", "medscape.com", "mayoclinic.org"],
            topic="general"
        )
        context_text = ""
        for result in response['results']:
            context_text += f"- SURSA: {result['title']}\n  URL: {result['url']}\n  INFO: {result['content']}\n\n"
        return context_text
    except Exception as e:
        return ""

def format_links(text):
    """TransformÄƒ linkurile markdown Ã®n linkuri HTML care se deschid Ã®n tab nou."""
    pattern = r'\[([^\]]+)\]\(([^)]+)\)'
    return re.sub(pattern, r'<a href="\2" target="_blank" style="color: #0068c9; font-weight: bold;">\1 ğŸ”—</a>', text)

# --- 5. GESTIONARE STARE (SESSION STATE) ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "patient_context" not in st.session_state:
    st.session_state.patient_context = ""
if "images_context" not in st.session_state:
    st.session_state.images_context = []

# --- 6. SIDEBAR (CONTROALE) ---
with st.sidebar:
    st.title("ğŸ©º Control Panel")
    st.caption(f"Model activ: `{model_name.split('/')[-1]}`")
    
    st.markdown("### âš™ï¸ SetÄƒri Asistent")
    
    # BUTONUL CERUT: Activare/Dezactivare Internet
    use_web_search = st.toggle("ğŸŒ CÄƒutare Web (Tavily)", value=True, help="DacÄƒ este activat, AI-ul va cÄƒuta cele mai recente studii/ghiduri. DacÄƒ e oprit, rÄƒspunde doar din cunoÈ™tinÈ›ele interne.")
    
    st.markdown("---")
    
    # MODUL CAZ CLINIC
    use_patient_mode = st.toggle("ğŸ“‚ Mod: Caz Clinic (Date Pacient)", value=False)
    
    if use_patient_mode:
        st.info("ğŸ“ Introdu datele anonimizate ale pacientului.")
        c1, c2, c3 = st.columns(3)
        with c1: gender = st.selectbox("Sex", ["M", "F"], label_visibility="collapsed")
        with c2: age = st.number_input("Ani", value=45, label_visibility="collapsed")
        with c3: weight = st.number_input("Kg", value=75, label_visibility="collapsed")
        
        uploaded_files = st.file_uploader("Analize (PDF) sau ImagisticÄƒ (Foto)", type=['pdf', 'png', 'jpg', 'jpeg'], accept_multiple_files=True)
        
        if uploaded_files:
            # Procesare automatÄƒ la upload
            raw_text = ""
            images = []
            for file in uploaded_files:
                if file.type == "application/pdf":
                    try:
                        reader = PdfReader(file)
                        for page in reader.pages:
                            raw_text += page.extract_text() + "\n"
                    except:
                        st.error("Eroare la citirea PDF-ului.")
                else:
                    images.append(Image.open(file))
            
            st.session_state.patient_context = raw_text
            st.session_state.images_context = images
            if raw_text or images:
                st.success(f"âœ… Dosar Ã®ncÄƒrcat: {len(images)} imagini, {len(raw_text)} caractere text.")
    else:
        # CurÄƒÈ›Äƒm contextul dacÄƒ se iese din modul pacient
        st.session_state.patient_context = ""
        st.session_state.images_context = []

    st.markdown("---")
    if st.button("ğŸ—‘ï¸ È˜terge ConversaÈ›ia", type="primary"):
        st.session_state.messages = []
        st.rerun()

# --- 7. INTERFAÈšA DE CHAT ---
st.subheader("ğŸ’¬ DiscuÈ›ie MedicalÄƒ")

# AfiÈ™are istoric
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if msg["role"] == "assistant":
            st.markdown(format_links(msg["content"]), unsafe_allow_html=True)
        else:
            st.markdown(msg["content"])

# --- 8. LOGICA DE PROCESARE (THE BRAIN) ---
if prompt := st.chat_input("ÃntreabÄƒ despre un tratament, un diagnostic sau datele pacientului..."):
    
    # AdÄƒugÄƒm mesajul utilizatorului Ã®n istoric
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        
        # A. CÄƒutare Web (Doar dacÄƒ butonul este activat)
        web_context_str = ""
        if use_web_search:
            with st.spinner("ğŸ” Caut informaÈ›ii medicale actualizate..."):
                search_res = search_tavily(prompt[:400])
                if search_res:
                    web_context_str = f"CONTEXT WEB (Surse Externe):\n{search_res}\n"
        
        # B. Construire Context Pacient
        patient_block = ""
        if use_patient_mode:
            # LimitÄƒm contextul pentru a evita erorile de prea mult text
            safe_context = st.session_state.patient_context[:5000] if st.session_state.patient_context else "Nu existÄƒ text extras."
            patient_block = f"""
            --- DATE PACIENT CURENT ---
            Sex: {gender}, VÃ¢rstÄƒ: {age}, Greutate: {weight}kg.
            REZUMAT DOSAR/ANALIZE: {safe_context} 
            (NotÄƒ: DacÄƒ existÄƒ imagini ataÈ™ate, analizeazÄƒ-le vizual).
            """
        
        # C. Construire Memorie (Istoric ConversaÈ›ie)
        history_str = ""
        # LuÄƒm ultimele 5 mesaje
        for m in st.session_state.messages[-6:-1]: 
            role_label = "MEDIC" if m["role"] == "user" else "AI"
            history_str += f"{role_label}: {m['content']}\n"

        # D. Promptul de Sistem - DEFINIT CU ATENÈšIE
        # Folosim concatenare simplÄƒ pentru a evita erorile de sintaxÄƒ la copy-paste
        base_instruction = """
        EÈ™ti un Consultant Medical Senior AI. DiscuÈ›i cu un coleg medic.
        SARCINI:
        1. RÄƒspunde concis, profesional È™i la obiect.
        2. FoloseÈ™te terminologie medicalÄƒ adecvatÄƒ.
        3. DacÄƒ primeÈ™ti CONTEXT WEB, foloseÈ™te-l prioritar È™i citeazÄƒ sursele [Sursa](URL).
        4. DacÄƒ primeÈ™ti DATE PACIENT, interpreteazÄƒ-le specific pentru acest caz.
        """
        
        # AsamblÄƒm promptul final
        final_prompt = f"{base_instruction}\n\n--- ISTORIC CONVERSAÈšIE ---\n{history_str}\n\n{web_context_str}\n\n{patient_block}\n\n--- ÃNTREBARE CURENTÄ‚ ---\nMEDIC: {prompt}"

        # E. Apelarea Modelului
        try:
            with st.spinner("Generare rÄƒspuns..."):
                content_parts = [final_prompt]
                
                # DacÄƒ avem imagini È™i suntem Ã®n mod pacient, le trimitem modelului
                if use_patient_mode and st.session_state.images_context:
                    content_parts.extend(st.session_state.images_context)
                
                response = model.generate_content(content_parts)
                response_text = response.text
                
                # AfiÈ™are
                final_html = format_links(response_text)
                response_placeholder.markdown(final_html, unsafe_allow_html=True)
                
                # Salvare Ã®n istoric
                st.session_state.messages.append({"role": "assistant", "content": response_text})
                
        except Exception as e:
            st.error(f"Eroare la generare: {str(e)}")
            st.info("Sfat: ÃncearcÄƒ sÄƒ reformulezi sau sÄƒ dezactivezi temporar cÄƒutarea web.")
