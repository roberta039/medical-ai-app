import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from PIL import Image
import re

# --- CONFIGURARE PAGINÄ‚ ---
st.set_page_config(page_title="MediChat Pro", page_icon="ğŸ©º", layout="wide")

# CSS Custom
st.markdown("""
    <style>
    .stChatMessage { font-family: 'Arial', sans-serif; }
    .stButton button { width: 100%; border-radius: 5px; }
    </style>
    """, unsafe_allow_html=True)

# Configurare API Key
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except:
    st.error("âš ï¸ Cheia API lipseÈ™te! Seteaz-o Ã®n Streamlit Secrets.")

# --- INITIALIZARE MODEL INTELIGENTÄ‚ ---
# Definim unealta de cÄƒutare Google NativÄƒ
google_search_tool = [{"google_search": {}}]

active_model_name = ""
has_search_capability = False

try:
    # 1. ÃncercÄƒm varianta IDEALÄ‚: Gemini 2.5 + Google Search
    model = genai.GenerativeModel('gemini-2.5-flash', tools=google_search_tool)
    active_model_name = "Gemini 2.5 (Google Search Activat)"
    has_search_capability = True
except Exception as e:
    try:
        # 2. DacÄƒ 2.0 nu merge, Ã®ncercÄƒm 1.5 + Google Search
        # (Unele conturi au acces, altele nu - testÄƒm)
        model = genai.GenerativeModel('gemini-1.5-flash', tools=google_search_tool)
        active_model_name = "Gemini 1.5 (Google Search Activat)"
        has_search_capability = True
    except:
        # 3. FALLBACK SIGUR: Gemini 1.5 (Memorie InternÄƒ)
        # Aici ajungem dacÄƒ Google Search e blocat pe cont. MÄƒcar AI-ul merge perfect.
        model = genai.GenerativeModel('gemini-1.5-flash')
        active_model_name = "Gemini 1.5 (ExpertizÄƒ InternÄƒ)"
        has_search_capability = False

# --- FUNCÈšII UTILITARE ---

def format_links_new_tab(text):
    """Link-uri Markdown -> HTML New Tab"""
    pattern = r'\[([^\]]+)\]\(([^)]+)\)'
    def replace_link(match):
        link_text = match.group(1)
        link_url = match.group(2)
        return f'<a href="{link_url}" target="_blank" style="color: #0068c9; text-decoration: none; font-weight: bold;">{link_text} ğŸ”—</a>'
    return re.sub(pattern, replace_link, text)

def reset_conversation():
    st.session_state.messages = []
    st.session_state.patient_context = ""
    st.session_state.images_context = []

def generate_download_text():
    text = "--- RAPORT CLINIC ---\n\n"
    for msg in st.session_state.messages:
        role = "MEDIC" if msg["role"] == "user" else "AI"
        text += f"{role}: {msg['content']}\n\n"
    return text

# --- INITIALIZARE STATE ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "patient_context" not in st.session_state:
    st.session_state.patient_context = ""
if "images_context" not in st.session_state:
    st.session_state.images_context = []

# --- SIDEBAR ---
with st.sidebar:
    st.title("ğŸ©º MediChat Pro")
    
    # Indicator Status
    if has_search_capability:
        st.success(f"âœ… {active_model_name}")
    else:
        st.info(f"ğŸ§  {active_model_name}")
        
    if st.button("ğŸ—‘ï¸ Resetare Caz", type="primary"):
        reset_conversation()
        st.rerun()
    
    st.markdown("---")
    
    use_patient_data = st.toggle("Mod: Caz Clinic", value=False)
    
    if use_patient_data:
        st.info("ğŸ“Š Date Pacient")
        col1, col2 = st.columns(2)
        with col1:
            gender = st.selectbox("Sex", ["M", "F"], label_visibility="collapsed")
        with col2:
            age = st.number_input("Ani", value=30, label_visibility="collapsed")
        weight = st.number_input("Greutate (kg)", value=70.0)
        uploaded_files = st.file_uploader("Dosar", type=['pdf', 'png', 'jpg'], accept_multiple_files=True)
        
        if st.button("ProceseazÄƒ Dosarul"):
            if uploaded_files:
                with st.spinner("Se citeÈ™te dosarul..."):
                    raw_text = ""
                    images = []
                    for file in uploaded_files:
                        if file.type == "application/pdf":
                            reader = PdfReader(file)
                            for page in reader.pages:
                                raw_text += page.extract_text() + "\n"
                        else:
                            images.append(Image.open(file))
                    st.session_state.patient_context = raw_text
                    st.session_state.images_context = images
                    st.success("Date Ã®ncÄƒrcate!")
    else:
        st.session_state.patient_context = ""
        st.session_state.images_context = []

    if st.session_state.messages:
        st.download_button("ğŸ’¾ Export DiscuÈ›ie", generate_download_text(), "consult.txt")

# --- CHAT ---
st.subheader("DiscuÈ›ie ClinicÄƒ")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message["role"] == "assistant":
            # AfiÈ™Äƒm È™i sursele Google dacÄƒ existÄƒ (Grounding)
            st.markdown(format_links_new_tab(message["content"]), unsafe_allow_html=True)
        else:
            st.markdown(message["content"])

if prompt := st.chat_input("Introdu datele clinice sau Ã®ntrebarea..."):
    
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("AnalizÄƒ Ã®n curs..."):
            try:
                # --- PROMPT DESIGN ---
                # DacÄƒ avem search activat, Ã®i spunem sÄƒ Ã®l foloseascÄƒ
                search_instruction = ""
                if has_search_capability:
                    search_instruction = """
                    FOLOSEÈ˜TE GOOGLE SEARCH: VerificÄƒ ghidurile actuale.
                    DacÄƒ gÄƒseÈ™ti surse relevante, include link-urile la final.
                    """

                system_prompt = f"""
                EÈ™ti un medic Consultant Senior (Peer-to-Peer).
                
                REGULI:
                1. RÄƒspunde colegial, tehnic È™i la obiect.
                2. FÄ‚RÄ‚ sfaturi pentru pacienÈ›i ("consultaÈ›i medicul"). Utilizatorul este medic.
                3. BazeazÄƒ-te pe expertiza ta internÄƒ + Search (dacÄƒ e disponibil).
                {search_instruction}
                """

                context_block = ""
                if use_patient_data:
                    context_block = f"""
                    DATE PACIENT: Sex: {gender}, VÃ¢rstÄƒ: {age}, Greutate: {weight}kg.
                    DOSAR: {st.session_state.patient_context}
                    """

                final_prompt = f"{system_prompt}\n{context_block}\nÃNTREBARE: {prompt}"

                content_parts = [final_prompt]
                if st.session_state.images_context and use_patient_data:
                    content_parts.append(st.session_state.images_context[0])

                # Generare (GestionÄƒm eroarea de 404 aici, local)
                try:
                    response = model.generate_content(content_parts)
                    
                    # AfiÈ™are rÄƒspuns
                    final_html = format_links_new_tab(response.text)
                    st.markdown(final_html, unsafe_allow_html=True)
                    
                    # AfiÈ™are surse Google Grounding (Metadate oficiale)
                    if hasattr(response.candidates[0], 'grounding_metadata'):
                        gm = response.candidates[0].grounding_metadata
                        if hasattr(gm, 'search_entry_point') and gm.search_entry_point:
                             st.caption(f"ğŸ” SursÄƒ VerificatÄƒ Google: {gm.search_entry_point.rendered_content}")

                    st.session_state.messages.append({"role": "assistant", "content": response.text})

                except Exception as e_gen:
                    # DacÄƒ modelul cu Search dÄƒ fail (404 sau altceva) Ã®n timpul generÄƒrii,
                    # facem fallback instant la modelul simplu (1.5) fÄƒrÄƒ sÄƒ È™tie utilizatorul.
                    fallback_model = genai.GenerativeModel('gemini-1.5-flash')
                    response = fallback_model.generate_content(content_parts)
                    
                    final_html = format_links_new_tab(response.text)
                    st.markdown(final_html, unsafe_allow_html=True)
                    st.caption("â„¹ï¸ RÄƒspuns generat din expertizÄƒ internÄƒ (Search indisponibil momentan).")
                    
                    st.session_state.messages.append({"role": "assistant", "content": response.text})

            except Exception as e:
                st.error(f"Eroare sistem: {e}")
